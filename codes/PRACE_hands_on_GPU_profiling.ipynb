{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVX2oYXw51FQ"
   },
   "source": [
    "# Hands-on: Profiling TensorFlow with TensorBoard\n",
    "\n",
    "\n",
    "![tb](https://github.com/tensorflow/tensorboard/blob/master/docs/images/quickstart_model_fit.png?raw=1)\n",
    "\n",
    "\n",
    "1. Download the notebook `PRACE_hands_on_GPU_profiling.ipynb` to your local system\n",
    "\n",
    "2. For this hands-on, we will use a jupyter notebook of Google where you can get a GPU for free named a \"Google Colaboratory\" environment so please navigate to the [colab link](https://colab.research.google.com/notebooks/intro.ipynb#recent=true)\n",
    "\n",
    "2. Navigate to `Upload` in the left upper corner\n",
    "\n",
    "3. Upload the `PRACE_hands_on_GPU_profiling.ipynb` by browsing to it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFd6o-3e51FS"
   },
   "source": [
    "First we need to run the following commands to use Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALZzJMLk51FT"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-datasets\n",
    "!pip install ipywidgets \n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "!pip install -U tensorboard-plugin-profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtW4IgM-51Fa"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NdWLQyGL51Fe"
   },
   "source": [
    "Now we are going to download the Fashion-MNIST dataset from Google, to train a dummy neural network which we will profile and inspect using Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvgIX8Wh51Fh"
   },
   "outputs": [],
   "source": [
    "# Download the data. The data is already divided into train and test.\n",
    "# The labels are integers representing classes.\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "    fashion_mnist.load_data()\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "\n",
    "# First let's construct the input pipeline throught the tf.data API (https://www.tensorflow.org/api_docs/python/tf/data)\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "ds_train = ds_train.map(normalize_img)\n",
    "ds_train = ds_train.batch(512)\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "ds_test = ds_test.map(normalize_img)\n",
    "ds_test = ds_test.batch(512)\n",
    "\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.Dense(128,activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFIJRzhp51Fk"
   },
   "source": [
    "- Now we are going to train the model for 5 epochs, where we make use of the Tensorboard callback to gather information on model training and performance which is stored in the `logs/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPaYhtun51Fl"
   },
   "outputs": [],
   "source": [
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, write_graph=True, write_images=True,\n",
    "    update_freq='epoch', profile_batch='2,3')\n",
    "\n",
    "\n",
    "%time model.fit(ds_train,epochs=5,validation_data=ds_test,callbacks = [tboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygLI8gBi51Fq"
   },
   "source": [
    "- Now start a Tensorboard instance, by inputting the commands, this might take a while. (If you start it for the **second** time may have to `!kill <pid>` a running process):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBnt3yzu6s6S"
   },
   "outputs": [],
   "source": [
    "#!kill 2037 \n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ly12iBi951Fr"
   },
   "source": [
    "- What are you seeing? Do you think we trained for enough epochs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T05PBamZ51Fs"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TYPE YOUR ANSWER HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Q3h9Rsn51Fw"
   },
   "source": [
    "### To see the profiling of the model, select \"Profile\" from the dropdown menu in the right upper corner where it says \"inactive\"\n",
    "- What is taking the longest time to compute? What percentage of compute time did it take? What was the duration of the GPU kernel of that operation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bVe57PJ51Fx"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TYPE YOUR ANSWER HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "erbQ3Q6J51F1"
   },
   "source": [
    "- Now take a look at the memory profile of the GPU, what do you think you can do to decrease free memory during training and make optimal use of the GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BECBS9s851F1"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TYPE YOUR ANSWER HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FK2fqYTH51F6"
   },
   "source": [
    "- What is the max duration of a GPU-kernel computation? What was the average wall duration of the compute stream that occurred the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0B7KEyh051F6"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TYPE YOUR ANSWER HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cmlg1dbJ51F9"
   },
   "source": [
    "- What do you think is in this case the bottleneck of the model? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JaBmzTmB51F9"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TYPE YOUR ANSWER HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7T3WOco51GB"
   },
   "source": [
    "- Use the `.cache()` and the `prefetch(tf.data.experimental.AUTOTUNE)` methods in your train and test data pipeline to optimize the speed of the training experiment\n",
    "- Run the model again, with the optimization in place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2tBwJEB51GB"
   },
   "source": [
    "- Why is the training now much faster? What has changed? How is this seen in the Tensorboard profiling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xuq9uqCt51GD"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TYPE YOUR ANSWER HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5NB0rBqv7JG6"
   },
   "source": [
    "### Next to the data pipeline, we can also optimize the speed and memory utilization through the floating point precision in which the model is training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAQi0RuL7eS8"
   },
   "source": [
    "- In what floating point precision is your model training right now, if you look at Tensorboard? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OP3iALVp7opR"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TYPE YOUR ANSWER HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uFovdfyo74u5"
   },
   "source": [
    "Now add the following commands above your model definition:\n",
    "```\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "```\n",
    "\n",
    "> This will set the `dtype` policy for building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1d96kC8k8kUU"
   },
   "source": [
    "- Now re-compile, and train your model. Did it lose any validation accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JF48bnHk83K-"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TYPE YOUR ANSWER HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wx_fmQMo83qY"
   },
   "source": [
    "- What are the ways in Tensorboard you can see the precision of the computations that took place? What do you notice? What is the max duration of a GPU-kernel computation now? Why didn't the model train faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIlNYxcf9JoQ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TYPE YOUR ANSWER HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ttGNsYbU51GH"
   },
   "source": [
    "- BONUS: If you're interested, try to improve this model with a [convolutional neural \n",
    "network](https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a) (CNN)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PRACE_hands_on.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
